{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88f965fd65caf53eecd694ad6de4975cb164e855"
   },
   "source": [
    "Converting json to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b5673a0-360b-416b-93f1-20ab0b47059c",
    "_uuid": "45434ba5eca05fa46ae502cbda4355987ed83f0b"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5825e5e2-95bf-448b-b6be-da3705cbbb09",
    "_uuid": "7304d7ccae288d5b3fc8a90af1c5575f2722f3e2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "adfc681e-5be2-4137-a1c5-bf9afc635c74",
    "_uuid": "6e00d35357ec987fe7aeb4db03717c67021245ee"
   },
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
    "                           verbose = 1):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    verbose: 0 to suppress it default is 1\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Reading the json file\")    \n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    if verbose:\n",
    "        print(\"processing...\")\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.json_normalize(file , record_path )\n",
    "    m = pd.json_normalize(file, record_path[:-1] )\n",
    "    r = pd.json_normalize(file,record_path[:-2])\n",
    "    \n",
    "    #combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
    "    m['context'] = idx\n",
    "    js['q_idx'] = ndx\n",
    "    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n",
    "    main['c_id'] = main['context'].factorize()[0]\n",
    "    if verbose:\n",
    "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
    "        print(\"Done\")\n",
    "    return main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d806c7fcad153644c08f0645a2a11dcbba0ba79"
   },
   "source": [
    "We have to define a different fuctions for Dev data because the the dev data is slightly different mainly there are multiple possible answer for a single question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "156c1fdb493acf8e2d197df2745478de38cde03c"
   },
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe_dev(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
    "                           verbose = 1):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    verbose: 0 to suppress it default is 1\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Reading the json file\")    \n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    if verbose:\n",
    "        print(\"processing...\")\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.json_normalize(file , record_path )\n",
    "    m = pd.json_normalize(file, record_path[:-1] )\n",
    "    r = pd.json_normalize(file,record_path[:-2])\n",
    "    \n",
    "    #combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "#     ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
    "    m['context'] = idx\n",
    "#     js['q_idx'] = ndx\n",
    "    main = m[['id','question','context','answers']].set_index('id').reset_index()\n",
    "    main['c_id'] = main['context'].factorize()[0]\n",
    "    if verbose:\n",
    "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
    "        print(\"Done\")\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1a63837c0a4be7eb3e52bfb81f1a1adebbb32b9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "input_file_path = 'train-v1.1.json'\n",
    "record_path = ['data','paragraphs','qas','answers']\n",
    "train = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "18ecd2d4-ae87-47f6-bb17-23a21c9ee6d3",
    "_uuid": "68b7c5b76641577d865b41c78123b7575620306d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f66f0a55-1f42-4c51-81a5-807454e41571",
    "_uuid": "79256a0869194b70275073451926bb65132ef19c"
   },
   "outputs": [],
   "source": [
    "# dev data\n",
    "input_file_path = 'dev-v1.1.json'\n",
    "record_path = ['data','paragraphs','qas','answers']\n",
    "verbose = 0\n",
    "dev = squad_json_to_dataframe_dev(input_file_path=input_file_path,record_path=record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2cd1487052b2930853e91d7db6ea8c5f0b112a25"
   },
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(dev['question'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "result_df = pd.concat([dev, tfidf_df], axis=1)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 374,
     "sourceId": 799923,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 20479,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
